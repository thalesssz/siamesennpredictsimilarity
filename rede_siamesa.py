# -*- coding: utf-8 -*-
"""rede_siamesa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N3--5rBwJtFbjS_lDGDPXilusbKS1wWU
"""

#!pip install gdown

import os
import random
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input,
    Conv2D,
    MaxPooling2D,
    Dense,
    Flatten,
    Lambda,
    Dropout,
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import ReduceLROnPlateau
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import gdown
import zipfile

file_id = "1vb781N3ZpWXceYx4OmQkqIdrio1y63So"
output_file = "imagens_final_modificado.zip"


if not os.path.isfile("imagens_final_modificado.zip"):
    gdown.download(f"https://drive.google.com/uc?id={file_id}", output_file)

with zipfile.ZipFile(output_file, "r") as zip_ref:
    zip_ref.extractall(".")


# Caminho para o diretório de imagens
image_dir = "./imagens_final_modificado"

# Encontrar todos os arquivos de imagem
image_files = [f for f in os.listdir(image_dir) if f.endswith(".png")]

# Ordenar os arquivos para garantir que os pares sejam adjacentes
image_files.sort()

# Listas para armazenar caminhos de imagens e rótulos
image_paths = []
labels = []

# Criar pares de imagens (modificadas e originais)
for i in range(0, len(image_files), 2):
    # Adicionando o par original-modificado
    image_paths.append(
        (
            os.path.join(image_dir, image_files[i]),
            os.path.join(image_dir, image_files[i + 1]),
        )
    )
    labels.append(1)  # 1 para imagens similares

    # Criando um par aleatório para dados negativos
    while True:
        random_image = random.choice(image_files)
        if random_image != image_files[i] and random_image != image_files[i + 1]:
            image_paths.append(
                (
                    os.path.join(image_dir, image_files[i]),
                    os.path.join(image_dir, random_image),
                )
            )
            labels.append(0)  # 0 para imagens diferentes
            break

# Embaralhar os pares de imagens e rótulos
combined = list(zip(image_paths, labels))
random.shuffle(combined)
image_paths[:], labels[:] = zip(*combined)


def process_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, [224, 224])
    image = image / 255.0  # Normalizar os valores dos pixels
    return image


# Processando as imagens
processed_images = [
    (process_image(pair[0]), process_image(pair[1])) for pair in image_paths
]

# Dividir dados em treino e teste
train_images, test_images, train_labels, test_labels = train_test_split(
    processed_images, labels, test_size=0.2, random_state=42
)

# Separando as imagens em dois grupos para entrada na rede siamesa
train_images_left = np.array([pair[0] for pair in train_images])
train_images_right = np.array([pair[1] for pair in train_images])

test_images_left = np.array([pair[0] for pair in test_images])
test_images_right = np.array([pair[1] for pair in test_images])

# Convertendo as labels para arrays do NumPy
train_labels = np.array(train_labels)
test_labels = np.array(test_labels)

# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# data_gen_args = dict(
#     rotation_range=20,
#     width_shift_range=0.2,
#     height_shift_range=0.2,
#     shear_range=0.2,
#     zoom_range=0.2,
#     horizontal_flip=True
# )

# data_gen = ImageDataGenerator(**data_gen_args)

# def generate_augmented_pairs(image_pairs, labels, batch_size):
#     while True:
#         # Embaralhar os pares e labels a cada nova época
#         indices = np.arange(len(image_pairs))
#         np.random.shuffle(indices)

#         num_batches = len(image_pairs) // batch_size

#         for batch_idx in range(num_batches):
#             batch_indices = indices[batch_idx * batch_size: (batch_idx + 1) * batch_size]
#             batch_pairs = [image_pairs[i] for i in batch_indices]
#             batch_labels = [labels[i] for i in batch_indices]

#             x_batch_left = []
#             x_batch_right = []

#             for pair in batch_pairs:
#                 # Gerando a mesma transformação para ambas as imagens no par
#                 seed = np.random.randint(1e6)
#                 x_batch_left.append(data_gen.random_transform(pair[0], seed=seed))
#                 x_batch_right.append(data_gen.random_transform(pair[1], seed=seed))

#             yield [np.array(x_batch_left), np.array(x_batch_right)], np.array(batch_labels)

# batch_size = 16
# steps_per_epoch = len(train_images) // batch_size

# model.compile(loss="binary_crossentropy", optimizer=Adam(0.0001), metrics=["accuracy"])

# tf.experimental.numpy.experimental_enable_numpy_behavior()
# model.fit(
#     generate_augmented_pairs(train_images, train_labels, batch_size),
#     steps_per_epoch=steps_per_epoch,
#     epochs=10,
#     validation_data=([test_images_left, test_images_right], test_labels)
# )


def build_siamese_model(input_shape):
    """
    Base network to be shared (siamese).
    """
    input = Input(shape=input_shape)

    # Adicionando camadas Conv2D e MaxPooling2D
    x = Conv2D(32, (3, 3), activation="relu")(input)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation="relu")(x)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(256, (3, 3), activation="relu")(x)
    x = MaxPooling2D((2, 2))(x)

    # Flatten e camadas Dense
    x = Flatten()(x)
    x = Dense(
        256,
        activation="relu",
    )(
        x
    )  # Aumentando o número de neurônios
    x = Dropout(0.1)(x)  # Ajuste da taxa de dropout
    x = Dense(256, activation="relu")(x)
    x = Dropout(0.1)(x)
    x = Dense(256, activation="relu")(x)
    x = Dropout(0.1)(x)

    return Model(input, x)


# Criando a rede siamesa
input_shape = (224, 224, 3)
base_network = build_siamese_model(input_shape)

# Definindo as entradas para as duas imagens
input_a = Input(shape=input_shape)
input_b = Input(shape=input_shape)

# Porque estou usando a mesma instância de 'base_network',
# os pesos serão compartilhados entre as duas imagens
processed_a = base_network(input_a)
processed_b = base_network(input_b)

# Adicionando a camada de distância
distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))(
    [processed_a, processed_b]
)


outputs = Dense(1, activation="sigmoid")(distance)
model = Model([input_a, input_b], outputs)

# # Função de distância euclidiana
# def euclidean_distance(vects):
#     x, y = vects
#     sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)
#     return K.sqrt(K.maximum(sum_square, K.epsilon()))

# # Sua função build_siamese_model permanece a mesma

# # Criando a rede siamesa
# input_shape = (224, 224, 3)
# base_network = build_siamese_model(input_shape)

# # Definindo as entradas para as duas imagens
# input_a = Input(shape=input_shape)
# input_b = Input(shape=input_shape)

# # Processando as duas imagens
# processed_a = base_network(input_a)
# processed_b = base_network(input_b)

# # Usando a função de distância euclidiana
# distance = Lambda(euclidean_distance)([processed_a, processed_b])

# outputs = Dense(1, activation="sigmoid")(distance)


# # Criando o modelo final
# model = Model([input_a, input_b], distance)

# # # Compilar o modelo
# # model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer='Adam')

# def contrastive_loss(y_true, y_pred):
#     # Convertendo y_true para o mesmo tipo que y_pred (float32)
#     y_true = tf.cast(y_true, tf.float32)

#     # Margem para a perda de contraste
#     margin = 1
#     # Calcular a parte da perda para os pares similares
#     square_pred = K.square(y_pred)
#     # Calcular a parte da perda para os pares não similares
#     margin_square = K.square(K.maximum(margin - y_pred, 0))
#     # Calcular a perda final
#     loss = K.mean(y_true * square_pred + (1 - y_true) * margin_square)
#     return loss

# def contrastive_loss_with_margin(margin):
#     def contrastive_loss(y_true, y_pred):
#         y_true = tf.cast(y_true, tf.float32)  # Garante que y_true seja float32
#         square_pred = tf.square(y_pred)
#         margin_square = tf.square(tf.maximum(margin - y_pred, 0))
#         return (y_true * square_pred + (1 - y_true) * margin_square)
#     return contrastive_loss

model.compile(loss="binary_crossentropy", optimizer=Adam(0.0001), metrics=["accuracy"])

# model.compile(loss=contrastive_loss, optimizer='adam', metrics=["accuracy"])
# margin = 1  # Define a margem desejada
# model.compile(loss=contrastive_loss_with_margin(margin), optimizer='Adam', metrics=["accuracy"])

# Cria um callback que reduz o learning_rate se não houver melhora na perda de validação
reduce_lr = ReduceLROnPlateau(
    monitor="val_loss", factor=0.2, patience=5, min_lr=0.00001
)

# Incluindo callback no treinamento
history = model.fit(
    [train_images_left, train_images_right],
    train_labels,
    epochs=30,
    validation_data=([test_images_left, test_images_right], test_labels),
    callbacks=[reduce_lr],
)

# Treinando o modelo - ORIGINAL
# model.fit(
#     [train_images_left, train_images_right],
#     train_labels,
#     validation_data=([test_images_left, test_images_right], test_labels),
#     batch_size=16,
#     epochs=20,
# )

# Avaliando o modelo no conjunto de teste
test_loss, test_accuracy = model.evaluate(
    [test_images_left, test_images_right], test_labels
)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

# Gráfico para a perda
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Perda durante o Treinamento e Validação")
plt.ylabel("Perda")
plt.xlabel("Época")
plt.legend()

# Gráfico para a acurácia
plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.title("Acurácia durante o Treinamento e Validação")
plt.ylabel("Acurácia")
plt.xlabel("Época")
plt.legend()

plt.show()


def predict_similarity(model, image_path1, image_path2):
    # Processar as imagens
    image1 = process_image(image_path1)
    image2 = process_image(image_path2)

    # Fazer a previsão
    prediction = model.predict(
        [np.expand_dims(image1, axis=0), np.expand_dims(image2, axis=0)]
    )

    # Interpretar o resultado
    similarity = prediction[0][0]
    if similarity > 0.5:  # limiar estabelecido empiricamente
        return "Similares", similarity
    else:
        return "Não similares", similarity


def display_images_with_prediction(model, image_path1, image_path2):
    # Fazendo a previsão
    prediction, similarity = predict_similarity(model, image_path1, image_path2)

    # Carregar as imagens
    img1 = plt.imread(image_path1)
    img2 = plt.imread(image_path2)

    # Exibir as imagens
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))
    axs[0].imshow(img1)
    axs[0].set_title("Imagem 1")
    axs[0].axis("off")

    axs[1].imshow(img2)
    axs[1].set_title("Imagem 2")
    axs[1].axis("off")

    plt.suptitle(
        f"Classificação da Rede: {prediction} \n(Similaridade: {similarity:.2f})"
    )
    plt.show()


# from tensorflow.keras.models import load_model
# model = load_model('/content/drive/MyDrive/meu_modelo.keras', safe_mode=False)

# caminho das imagens para predição

image_path1 = "./imagens_final_modificado/13 (2).png"
image_path2 = "./imagens_final_modificado/13.png"

display_images_with_prediction(model, image_path1, image_path2)

predictions = model.predict([test_images_left, test_images_right])
predicted_labels = (predictions > 0.5).astype("int").flatten()

cm = confusion_matrix(test_labels, predicted_labels)

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()

# model.save('meu_modelo.h5')  # Salva o modelo
# model.save('meu_modelo.keras')

# !mv "/content/meu_modelo.keras" "/content/drive/MyDrive/"
